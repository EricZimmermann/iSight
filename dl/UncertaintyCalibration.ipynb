{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Ensemble Calibration for Uncertainty Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "import os \n",
    "\n",
    "# data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# deep learning \n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# custom helpers\n",
    "import trainer\n",
    "import uncertainty \n",
    "import process\n",
    "import inference\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './balanced_ensembles'\n",
    "device = torch.device('cuda:0')\n",
    "num_workers = 1\n",
    "batch_size = 128\n",
    "n_cls = 7\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "in_ftr  = model.fc.in_features\n",
    "model.fc = nn.Linear(in_ftr,n_cls,bias=True)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPickle(fp):\n",
    "    with open(fp, 'rb') as handle:\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(model, fp, data):\n",
    "    pred_outputs = []\n",
    "    label_outputs = []\n",
    "    \n",
    "    for f in sorted(os.listdir(fp)):\n",
    "        full_model_path = os.path.join(fp, f)\n",
    "        model.load_state_dict(torch.load(full_model_path))\n",
    "        val_set = process.SkinSet(data['validation'])\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "        batch_total = 0.0\n",
    "        labels = []\n",
    "        predictions = [] \n",
    "    \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (inputs, targets) in enumerate(val_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                preds = F.softmax(model(inputs), dim=1)\n",
    "                labels.extend(targets.detach().cpu().numpy())\n",
    "                predictions.extend(preds.detach().cpu().numpy())\n",
    "\n",
    "        pred_outputs.append(predictions)\n",
    "        label_outputs.append(labels)\n",
    "        \n",
    "    return np.array(pred_outputs), np.array(label_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Mean/Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadPickle('./balanced_exp.pickle')\n",
    "preds, labels = compute(model, path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 998, 7) (6, 998)\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Acc 1 : 0.8196392785571143\n",
      "Model Acc 2 : 0.7805611222444889\n",
      "Model Acc 3 : 0.843687374749499\n",
      "Model Acc 4 : 0.8276553106212425\n",
      "Model Acc 5 : 0.8246492985971944\n",
      "Model Acc 6 : 0.814629258517034\n",
      "Model Bal Acc 1 : 0.766710621991389\n",
      "Model Bal Acc 2 : 0.6850030397585104\n",
      "Model Bal Acc 3 : 0.7703654929810695\n",
      "Model Bal Acc 4 : 0.7309029073842401\n",
      "Model Bal Acc 5 : 0.7990184831691344\n",
      "Model Bal Acc 6 : 0.8135194690111399\n",
      "Mean Acc: 0.8184702738810955\n",
      "Mean Bal Acc: 0.7609200023825805\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "bal_acc = []\n",
    "for m in preds:\n",
    "    p = []\n",
    "    for val in m:\n",
    "        p.append(np.argmax(val))\n",
    "        \n",
    "    acc.append(accuracy_score(labels[0], p))\n",
    "    bal_acc.append(balanced_accuracy_score(labels[0], p))\n",
    "c = 0\n",
    "for v in acc:\n",
    "    c += 1\n",
    "    print(\"Model Acc\", c, ':', v)\n",
    "c = 0\n",
    "for v in bal_acc:\n",
    "    c += 1\n",
    "    print(\"Model Bal Acc\", c, ':', v)\n",
    "    \n",
    "print(\"Mean Acc:\", np.mean(acc))\n",
    "print(\"Mean Bal Acc:\", np.mean(bal_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998, 7)\n",
      "(7,)\n",
      "[0.0113876  0.015099   0.01973732 0.00275105 0.02780673 0.02693587\n",
      " 0.00160483]\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(preds, 0)\n",
    "r_var = np.var(preds,0)\n",
    "var = np.mean(np.var(preds,0), 0)\n",
    "\n",
    "print(mean.shape)\n",
    "print(var.shape)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.8817635270541082\n",
      "Ensemble Balanced Accuracy: 0.8730295552851854\n"
     ]
    }
   ],
   "source": [
    "p = []\n",
    "for val in mean:\n",
    "    p.append(np.argmax(val))\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(labels[0], p))\n",
    "print(\"Ensemble Balanced Accuracy:\", balanced_accuracy_score(labels[0], p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove bottom 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeExclude(model, fp, data, exclude):\n",
    "    pred_outputs = []\n",
    "    label_outputs = []\n",
    "    \n",
    "    for idx, f in enumerate(sorted(os.listdir(fp))):\n",
    "        if idx in exclude: continue\n",
    "        full_model_path = os.path.join(fp, f)\n",
    "        model.load_state_dict(torch.load(full_model_path))\n",
    "        val_set = process.SkinSet(data['validation'])\n",
    "        val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "        batch_total = 0.0\n",
    "        labels = []\n",
    "        predictions = [] \n",
    "    \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (inputs, targets) in enumerate(val_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                preds = F.softmax(model(inputs), dim=1)\n",
    "                labels.extend(targets.detach().cpu().numpy())\n",
    "                predictions.extend(preds.detach().cpu().numpy())\n",
    "\n",
    "        pred_outputs.append(predictions)\n",
    "        label_outputs.append(labels)\n",
    "        \n",
    "    return np.array(pred_outputs), np.array(label_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labels = computeExclude(model, path, data, [1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(preds, 0)\n",
    "r_var = np.var(preds,0)\n",
    "var = np.mean(np.var(preds,0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.8707414829659319\n",
      "Ensemble Balanced Accuracy: 0.8790445834880132\n"
     ]
    }
   ],
   "source": [
    "p = []\n",
    "for val in mean:\n",
    "    p.append(np.argmax(val))\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(labels[0], p))\n",
    "print(\"Ensemble Balanced Accuracy:\", balanced_accuracy_score(labels[0], p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = list(data['test'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conf': False, 'disease': 'Melanocytic Nevi', 'prob': 0.62132996}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Melanoma'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = IDs[np.random.randint(len(IDs))]\n",
    "results = inference.infer('/usr/local/data/ezimmer/implementAI2020/dl/data/HAM/images/'+ID+'.jpg', path)\n",
    "pprint(results)\n",
    "inverse_mapping = {0:\"Bowen's Disease\", \n",
    "                   1:\"Basal Cell Carcinoma\", \n",
    "                   2:'Benign Keratosis-like Lesions', \n",
    "                   3:'Dermatofibroma', \n",
    "                   4:'Melanoma', \n",
    "                   5:'Melanocytic Nevi', \n",
    "                   6:'Vascular Lesions'} \n",
    "inverse_mapping[data['test'][ID]['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(path, 'model_2.pth.tar')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.softmax(model(torch.tensor((np.load(data['test'][ID]['image']))).unsqueeze(0).to(device)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7803e-05, 9.9263e-06, 4.5048e-03, 5.1321e-06, 7.8747e-01, 2.0799e-01,\n",
      "         4.6164e-07]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(x, x.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 600, 3)\n",
      "torch.Size([1, 3, 225, 300])\n"
     ]
    }
   ],
   "source": [
    "import skimage.io as io\n",
    "from skimage.transform import resize\n",
    "img = io.imread('/usr/local/data/ezimmer/implementAI2020/dl/data/HAM/images/'+ID+'.jpg').astype(np.float32)\n",
    "print(img.shape)\n",
    "img = resize(img, (225,300,3)).transpose(2,0,1) / 255.0\n",
    "img = torch.tensor(img).unsqueeze(0).to(device)\n",
    "print(img.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.softmax(model(img), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7803e-05, 9.9263e-06, 4.5048e-03, 5.1321e-06, 7.8747e-01, 2.0799e-01,\n",
      "         4.6164e-07]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 225, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(data['test'][ID]['image']).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
